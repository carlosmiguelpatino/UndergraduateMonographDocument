\chapter{Signal Simulation and Analysis} 

\section{Simulation Computational Resources} \label{sec: simulation}


The project required computational work, because simulations of events from the different processes were needed. Also, an analysis of the samples using the analysis code was required. The background and signal samples were simulated using the software MadGraph \cite{MadGraph}, Pythia \cite{Pythia} and Delphes \cite{Delphes}. The data analysis and all the subsequent kinematic, topological, and optimal cuts analyses were performed using ROOT software \cite{ROOT}.

MadGraph is an event generator software that allows the simulation of collision between two particle beams. For this analysis in particular, the simulations will consist in proton-proton collisions at 13 TeV in order to emulate the actual conditions of the LHC. MadGraph includes the physical parameters that determine the production probability of a given process, as well as the possible decays of the simulated particles. Besides providing the necessary matrices to calculate the cross sections of the processes, MadGraph also creates the pictorial representations of the Feynman Diagrams from the generated processes. To this end, the software uses perturbation theory in the calculations of production and generation of physical processes.

Pythia is a software that allows the simulation of various strong processes models that evolve from a few bodies to final states with high particle multiplicity. Particularly, in this case Pythia will be used for the simulation of quark and gluon fragmentation processes. This fragmentation process occurs when, due to and intrinsic characteristic of the strong interaction, there is an energy gain caused by the increase of the distance of two bound quarks. If the separation is enough to reach a critical energy, a pair quark-antiquark is created. The Pythia simulation is necessary, because processes like the ones mentioned above occur during a proton collision at the LHC.

Delphes is a software used to add to the simulation the effects that a multipurpose detector, like ATLAS or CMS, may have on the particles. In this particular case, Delphes is necessary to simulate the interaction of the particles coming from the generated processes in MadGraph and Pythia with the CMS components. Namely, reproducing the conditions of the detector and the uncertainties coming from the measuring process is achieved by using Delphes. The changes in the kinematic variables due to their interaction with matter, errors caused by the electronics of the detector, and the additional particles generated because of the interaction between the particles and the detector components can be accounted for using Delphes. Other functionalities included in Delphes are: simulation of the detector geometry, the effect of the magnetic field over the particles, and the particle identification and reconstruction efficiencies, among others.


\section{Simulation Process}

The MadGraph signal simulation was performed for six values of the heavy neutrino masses: 0.1, 0.5, 1.0, 1.25, 1.5, and 2.0 TeV. Also, taking into account that the analysis was going to be performed using VBF, the paramater of minimum pseudorapidity separation ($\Delta \eta$) between two jets was set to 3.5. This parameter allowed to have more events with the VBF topology in the simulation.

The commands used to generate the desired signal were the following:

\begin{itemize}
\item import model SM\_HeavyN\_NLO
\item generate p p $>$ n3 ta+ jj, QCD= 0, n3 $>$ ta+ jj
\item add process p p $>$ n3 ta+ jj, QCD= 0, n3 $>$ ta- jj
\item add process p p $>$ n3 ta- jj, QCD= 0, n3 $>$ ta- jj
\item add process p p $>$ n3 ta- jj, QCD= 0, n3 $>$ ta+ jj

\end{itemize}

The first command imports the theoretical model that includes the interactions related with the heavy neutrino formation and decay. The next command specifies the processes that are going to be simulated. pp $>$ n3 ta+ jj stands por the proton-proton collision that decays into a heavy neutrino, a $\tau$ with positive charge, and two jets. The flag QCD=0 is used to exclude all strong interactions that can be involved in the process. Finally, n3 $>$ ta+ jj is used to force the decay of the heavy neutrino into a $\tau$ charged positively and two jets. The subsequent commands are used to take into account all the possible combinations of the electrical charge that the $\tau$ may have. The additional parameter mentioned earlier of a separation greater than 3.5, i.e. $\Delta \eta > 3.5$, between VBF jets was included in run card of the simulation. 


Each simulation was for 100,000 events. The simulation for the 1.5 TeV mass value was performed in 10 different simulation batches each one containing 10,000 events. Every batch was generated with a different random seed to guarantee the independence of the events between each one of the generated batches. This independence was necessary because the 10,000 event files were merged to form a single file with 100,000 events. The other three simulations were performed in a single run of 100,000 events each.

As explained earlier, after the events were simulated in MadGraph they were passed to Pythia and then to Delphes so the signal resembled one that could be found at a particle detector. Delphes has configuration cards that emulate the conditions of ATLAS and CMS. In our analysis, the card from CMS was used. The Pythia process using Pythia 6 and MadGraph 5 was done seamlessly, because Pythia 6 is intergrated directly into MadGraph 5. This functionality makes that, to perform the Pythia simulation process, it is enough to turn on Pythia at the beginning of the MadGraph 5 simulation commands. To perform the Delphes simulation part, the output files from Pythia and MadGraph were used to execute a Delphes simulation.

\section{Analysis Computational Resources}

As mentioned earlier, the ROOT framework was used to perform all the analyses regarding kinematic and topological variables, and optimal cuts. ROOT is a software library developed by CERN to perform data analyses related with particle physics. One of the main characteristics of this library is the possibility of handling large volumes of data efficiently. The latter is achieved by using a tree structure in which the information related with the particles is stored and can be accessed easily using ROOT functionalities. Other features included in the library are the creation of histograms from data trees, multivariate analysis, four-vector calculations, among others. By using ROOT functionalities, it is also possible to estimate optimal cuts in variables to reduce experimental noise to its minimum. This is why the entire final analysis involved using tools provided by ROOT. A more detailed description of the analysis performed using ROOT is presented in the following chapters.

